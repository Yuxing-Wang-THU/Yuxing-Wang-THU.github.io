<hr>
<h2 align="center">A Surrogate-Assisted Controller for Expensive Evolutionary Reinforcement Learning<h2></h2>

<p align="center">Yuxing Wang, Tiantian Zhang, Yongzhe Chang, Bin Liang, Xueqian Wang, Bo Yuan</p>

</br>
<div align="center"><img src="/assets/img/publication_preview/serl.jpg" width="500"></div>

<p style="text-align:justify;"><strong>Abstract:</strong> The integration of Reinforcement Learning (RL) and Evolutionary Algorithms (EAs) aims at simultaneously exploiting the sample efficiency as well as the diversity and robustness of the two paradigms. Recently, hybrid learning frameworks based on this principle have achieved great success in robot control tasks. However, in these methods, policies from the genetic population are evaluated via interactions with the real environments, severely restricting their applicability when such interactions are prohibitively costly. In this work, we propose Surrogate-assisted Controller (SC), a generic module that can be applied on top of existing hybrid frameworks to alleviate the computational burden of expensive fitness evaluation. At the heart of SC is a novel surrogate model based on the critic network in RL, which efficiently leverages historical interaction data generated by the population and makes it possible to estimate the fitness of individuals without environmental interactions. In addition, two model management strategies with the elite protection mechanism are introduced in SC to control the workflow, leading to a fast and stable optimization process. In the empirical studies, we combine SC with two state-of-the-art evolutionary reinforcement learning approaches to highlight its functionality and effectiveness. Experiments on six challenging continuous control benchmarks from the OpenAI Gym platform show that SC can not only significantly reduce the cost of interaction with the environment, but also bring better sample efficiency and dramatically boost the learning progress of the original hybrid framework.</p>
<p>ðŸ“‚ <a href="https://www.sciencedirect.com/science/article/abs/pii/S0020025522012658">Download paper here!</a><br>
ðŸ‘‰ <a href="https://github.com/Yuxing-Wang-THU/Surrogate-assisted-ERL">Code is available here!</a><br></p>
<p><strong>Bibtex</strong><br></p>
<pre class="language-bash"><code class="language-bash code-highlight"><span class="code-line line-number" line="1">@article<span class="token punctuation">{</span>wang2022surrogate,
</span><span class="code-line line-number" line="2">  <span class="token assign-left variable">title</span><span class="token operator">=</span><span class="token punctuation">{</span>A surrogate-assisted controller <span class="token keyword">for</span> expensive evolutionary reinforcement learning<span class="token punctuation">}</span>,
</span><span class="code-line line-number" line="3">  <span class="token assign-left variable">author</span><span class="token operator">=</span><span class="token punctuation">{</span>Wang, Yuxing and Zhang, Tiantian and Chang, Yongzhe and Wang, Xueqian and Liang, Bin and Yuan, Bo<span class="token punctuation">}</span>,
</span><span class="code-line line-number" line="4">  <span class="token assign-left variable">journal</span><span class="token operator">=</span><span class="token punctuation">{</span>Information Sciences<span class="token punctuation">}</span>,
</span><span class="code-line line-number" line="5">  <span class="token assign-left variable">volume</span><span class="token operator">=</span><span class="token punctuation">{</span><span class="token number">616</span><span class="token punctuation">}</span>,
</span><span class="code-line line-number" line="6">  <span class="token assign-left variable">pages</span><span class="token operator">=</span><span class="token punctuation">{</span><span class="token number">539</span>--557<span class="token punctuation">}</span>,
</span><span class="code-line line-number" line="7">  <span class="token assign-left variable">year</span><span class="token operator">=</span><span class="token punctuation">{</span><span class="token number">2022</span><span class="token punctuation">}</span>,
</span><span class="code-line line-number" line="8">  <span class="token assign-left variable">publisher</span><span class="token operator">=</span><span class="token punctuation">{</span>Elsevier<span class="token punctuation">}</span>
</span><span class="code-line line-number" line="9"><span class="token punctuation">}</span>
</span></code></pre>
<p>ðŸŽ¦<strong>Video</strong></p>
<p>A HalfCheetah agent trained by SPDERL-I with average performance of 14000 points over 50 test seeds.</p>
<video id="video0" controls="" preload="True" width="510">
    <source id="0mp4" src="/assets/img/2.HalfCheetah_trained_by_SPDERL-I_14000.mp4" type="video/mp4">
</video>
<p>A Hopper agent trained by SPDERL-I with average performance of 4100 points over 50 test seeds.</p>
<video id="video1" controls="" preload="True" width="510">
    <source id="1mp4" src="/assets/img/3.Hopper_trained_by_SPDERL-I_4100.mp4" type="video/mp4">
</video>
<p>A Walker agent trained by SPDERL-I with average performance of 9000 points over 50 test seeds.</p>
<video id="video2" controls="" preload="True" width="510">
    <source id="2mp4" src="/assets/img/6.Walker_trained_by_SPDERL-G_9000.mp4" type="video/mp4">
</video>


